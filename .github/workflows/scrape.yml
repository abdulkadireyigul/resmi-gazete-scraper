name: Scrape Resmi Gazete and Update RSS

on:
  # Zamanlanmış Çalıştırma (Günde 3 kez: UTC 05:00, 11:00, 17:00 - Türkiye saatiyle 08:00, 14:00, 20:00 gibi)
  schedule:
    - cron: '0 5,11,17 * * *' 
  # Manuel Çalıştırma (GitHub Arayüzünden "Run workflow" butonu ile)
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest # Workflow'un çalışacağı sanal makine
    permissions:
       contents: write # Repoya dosya yazma (commit/push) izni

    steps:
      # 1. Adım: Repodaki kodları sanal makineye indir (checkout)
      - name: Check out repository code
        uses: actions/checkout@v4

      # 2. Adım: Python ortamını kur
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10' # Kullandığın Python sürümüne yakın bir sürüm seçebilirsin

      # 3. Adım: Gerekli Python kütüphanelerini yükle
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # 4. Adım: Scraper script'ini çalıştır
      - name: Run scraper
        env:
          PROXY_HOST: ${{ secrets.PROXY_HOST }}
          PROXY_PORT: ${{ secrets.PROXY_PORT }}
          PROXY_USERNAME: ${{ secrets.PROXY_USERNAME }}
          PROXY_PASSWORD: ${{ secrets.PROXY_PASSWORD }}
          CF_WORKER_PROXY: ${{ secrets.CF_WORKER_PROXY }}
        run: python scraper.py

      # 5. Adım: Değişiklikleri (varsa) repoya commit'le ve push'la
      - name: Commit and push changes
        run: |
          git config --global user.name 'github-actions[bot]' # Commit'i yapacak bot adı
          git config --global user.email 'github-actions[bot]@users.noreply.github.com' # Bot email
          # Sadece resmi_gazete.xml ve last_processed.json dosyalarında değişiklik varsa commit at
          git add resmi_gazete.xml last_processed.json
          # Değişiklik olup olmadığını kontrol et, varsa commit at ve pushla
          git diff --staged --quiet || git commit -m "Update RSS feed and state"
          git push